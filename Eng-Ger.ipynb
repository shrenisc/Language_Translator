{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05b7814-38ba-4d3f-bcc9-4adab02ef2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad3bf0c-ce35-4ef7-b657-de7ade8c69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"eng-ger.csv\")\n",
    "english_sentences=data[\"ENGLISH\"].head(10000).tolist()\n",
    "german_sentences=data[\"GERMAN\"].head(10000).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80885643-19df-4b4c-845e-64d69b5c03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize English sentences\n",
    "tokenizer_eng = Tokenizer()\n",
    "tokenizer_eng.fit_on_texts(english_sentences)\n",
    "total_words_eng = len(tokenizer_eng.word_index) + 1\n",
    "\n",
    "# Tokenize German sentences\n",
    "tokenizer_ger = Tokenizer()\n",
    "tokenizer_ger.fit_on_texts(german_sentences)\n",
    "total_words_ger = len(tokenizer_ger.word_index) + 1\n",
    "\n",
    "# Convert sentences to sequences\n",
    "input_sequences = tokenizer_eng.texts_to_sequences(english_sentences)\n",
    "output_sequences = tokenizer_ger.texts_to_sequences(german_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd11ac4-14c8-4d61-9d81-af25ca8539f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save reverse word index to JSON files\n",
    "import json\n",
    "\n",
    "with open('tokenizer_eng.json', 'w') as f:\n",
    "    json.dump(tokenizer_eng.to_json(), f)\n",
    "\n",
    "with open('tokenizer_ger.json', 'w') as f:\n",
    "    json.dump(tokenizer_ger.to_json(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e320a0-d0ff-44fc-b1eb-7a3f4eeb97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to have the same length\n",
    "max_len = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in output_sequences))\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5acb82-ac27-4553-a5db-7e65d79ab566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create input and output for the model\n",
    "X = np.array(input_sequences)\n",
    "y = np.array(output_sequences)\n",
    "\n",
    "# Convert target labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y, num_classes=total_words_ger)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179fed38-ab0c-48b3-b918-bbbdbeb4346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(total_words_eng, 128, input_length=max_len))\n",
    "# model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(total_words_ger, activation='softmax'))\n",
    "\n",
    "# # Compile the model with Adam optimizer and categorical_crossentropy loss\n",
    "# optimizer = Adam(learning_rate=0.001)\n",
    "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Learning rate scheduler\n",
    "# def lr_schedule(epoch):\n",
    "#     if epoch < 10:\n",
    "#         return 0.001\n",
    "#     else:\n",
    "#         return 0.0001\n",
    "\n",
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30b8049-735f-456b-ad13-7e5b16809684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "250/250 [==============================] - 89s 356ms/step - loss: 1.9598 - accuracy: 0.8499 - val_loss: 1.0106 - val_accuracy: 0.9113\n",
      "Epoch 2/8\n",
      "250/250 [==============================] - 71s 285ms/step - loss: 0.5692 - accuracy: 0.9297 - val_loss: 1.1683 - val_accuracy: 0.8883\n",
      "Epoch 3/8\n",
      "250/250 [==============================] - 70s 280ms/step - loss: 0.4939 - accuracy: 0.9364 - val_loss: 0.6452 - val_accuracy: 0.9275\n",
      "Epoch 4/8\n",
      "250/250 [==============================] - 69s 277ms/step - loss: 0.4313 - accuracy: 0.9410 - val_loss: 0.4875 - val_accuracy: 0.9413\n",
      "Epoch 5/8\n",
      "250/250 [==============================] - 69s 276ms/step - loss: 0.3647 - accuracy: 0.9454 - val_loss: 0.4616 - val_accuracy: 0.9430\n",
      "Epoch 6/8\n",
      "250/250 [==============================] - 77s 307ms/step - loss: 0.2996 - accuracy: 0.9505 - val_loss: 0.4075 - val_accuracy: 0.9465\n",
      "Epoch 7/8\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.2340 - accuracy: 0.9558 - val_loss: 0.3725 - val_accuracy: 0.9493\n",
      "Epoch 8/8\n",
      "250/250 [==============================] - 88s 351ms/step - loss: 0.1919 - accuracy: 0.9599 - val_loss: 0.3655 - val_accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x201340afa00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Train the model with callbacks\n",
    "# model.fit(X_train, y_train, epochs=8, validation_data=(X_test, y_test), callbacks=[lr_scheduler, early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37af279-731b-459c-9385-340e74819c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 8s 122ms/step - loss: 0.3655 - accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "# # Evaluate on test set\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad6e329-08b1-494a-8506-8909312bab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"language_translation_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5f448f-34fc-4b13-b1c3-8475959b3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"max_len.txt\", \"w\") as f:\n",
    "    f.write(str(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efed7c93-0e6e-408f-a0fc-4761f44d1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "loaded_model = load_model(\"language_translation_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1f3e611-a5ca-491e-9ac4-89d67227381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an English sentence:  i am studying\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Translation: ich lerne sehr\n"
     ]
    }
   ],
   "source": [
    "# Take input from the user\n",
    "user_input = input(\"Enter an English sentence: \")\n",
    "\n",
    "# Tokenize and pad the input sequence\n",
    "input_seq = tokenizer_eng.texts_to_sequences([user_input])\n",
    "input_seq = pad_sequences(input_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# Predict the output sequence\n",
    "predicted_seq = loaded_model.predict(input_seq)\n",
    "\n",
    "predicted_text = []\n",
    "for word_index in np.argmax(predicted_seq, axis=-1)[0]:\n",
    "    if word_index != 0:  # Ignore padding index\n",
    "        word = tokenizer_ger.index_word.get(word_index, '<OOV>')\n",
    "        predicted_text.append(word)\n",
    "\n",
    "# Display the result\n",
    "german_translation = ' '.join(predicted_text)\n",
    "print(f\"German Translation: {german_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38ce1a-8d27-4abf-bdb4-dd99da19d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
